{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a19324f4-2743-40ff-8391-0d9b25060242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tên các cột: ['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species']\n",
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n",
      "\n",
      "Có giá trị thiếu không:\n",
      "Id               0\n",
      "SepalLengthCm    0\n",
      "SepalWidthCm     0\n",
      "PetalLengthCm    0\n",
      "PetalWidthCm     0\n",
      "Species          0\n",
      "dtype: int64\n",
      "Số mẫu train: 105\n",
      "Số mẫu test: 45\n",
      "Độ chính xác trên tập test: 0.9777777777777777\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        15\n",
      "Iris-versicolor       0.94      1.00      0.97        15\n",
      " Iris-virginica       1.00      0.93      0.97        15\n",
      "\n",
      "       accuracy                           0.98        45\n",
      "      macro avg       0.98      0.98      0.98        45\n",
      "   weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  1 14]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "df = pd.read_csv(\"Iris.csv\")\n",
    "\n",
    "print(\"Tên các cột:\", df.columns.tolist())\n",
    "print(df.head())\n",
    "\n",
    "X = df.iloc[:, :-1].values  \n",
    "y = df.iloc[:, -1].values   \n",
    "\n",
    "print(\"\\nCó giá trị thiếu không:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Số mẫu train:\", X_train.shape[0])\n",
    "print(\"Số mẫu test:\", X_test.shape[0])\n",
    "\n",
    "class NaiveBayes:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.mean = {}\n",
    "        self.var = {}\n",
    "        self.priors = {}\n",
    "\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            self.mean[c] = X_c.mean(axis=0)\n",
    "            self.var[c] = X_c.var(axis=0)\n",
    "            self.priors[c] = X_c.shape[0] / X.shape[0]\n",
    "\n",
    "    def _pdf(self, class_idx, x):\n",
    "        mean = self.mean[class_idx]\n",
    "        var = self.var[class_idx]\n",
    "        numerator = np.exp(- (x - mean) ** 2 / (2 * var))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        return numerator / denominator\n",
    "\n",
    "    def _predict_single(self, x):\n",
    "        posteriors = []\n",
    "        for c in self.classes:\n",
    "            prior = np.log(self.priors[c])\n",
    "            conditional = np.sum(np.log(self._pdf(c, x)))\n",
    "            posterior = prior + conditional\n",
    "            posteriors.append(posterior)\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_single(x) for x in X])\n",
    "\n",
    "nb = NaiveBayes()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print(\"Độ chính xác trên tập test:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aae6802a-9826-4abe-8308-015cbfde80d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số mẫu: 20000 Số feature: 16\n",
      "Số lớp: 26\n",
      "Một số dòng đầu tiên:\n",
      "  0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16\n",
      "0  T   2   8   3   5   1   8  13   0   6   6  10   8   0   8   0   8\n",
      "1  I   5  12   3   7   2  10   5   5   4  13   3   9   2   8   4  10\n",
      "2  D   4  11   6   8   6  10   6   2   6  10   3   7   3   7   3   9\n",
      "3  N   7  11   6   6   3   5   9   4   6   4   4  10   6  10   2   8\n",
      "4  G   2   1   3   1   1   8   6   6   6   6   5   9   1   7   5  10\n",
      "Số mẫu train: 14000\n",
      "Số mẫu test: 6000\n",
      "Accuracy trên Letter dataset: 0.6448333333333334\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.83      0.84      0.84       237\n",
      "           B       0.47      0.72      0.57       230\n",
      "           C       0.79      0.80      0.80       221\n",
      "           D       0.58      0.73      0.65       242\n",
      "           E       0.58      0.36      0.44       230\n",
      "           F       0.69      0.77      0.73       232\n",
      "           G       0.58      0.54      0.56       232\n",
      "           H       0.55      0.33      0.41       220\n",
      "           I       0.53      0.72      0.61       226\n",
      "           J       0.84      0.72      0.78       224\n",
      "           K       0.46      0.49      0.47       222\n",
      "           L       0.92      0.77      0.84       228\n",
      "           M       0.69      0.88      0.78       238\n",
      "           N       0.87      0.68      0.77       235\n",
      "           O       0.48      0.73      0.58       226\n",
      "           P       0.88      0.77      0.82       241\n",
      "           Q       0.52      0.49      0.50       235\n",
      "           R       0.62      0.65      0.64       227\n",
      "           S       0.29      0.27      0.28       224\n",
      "           T       0.70      0.69      0.70       239\n",
      "           U       0.86      0.74      0.80       244\n",
      "           V       0.71      0.83      0.76       229\n",
      "           W       0.73      0.84      0.78       226\n",
      "           X       0.44      0.43      0.43       236\n",
      "           Y       0.68      0.34      0.45       236\n",
      "           Z       0.78      0.60      0.67       220\n",
      "\n",
      "    accuracy                           0.64      6000\n",
      "   macro avg       0.66      0.64      0.64      6000\n",
      "weighted avg       0.66      0.64      0.64      6000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[200   0   0   1   0   0   0   3   0   1   5   0   5   2   0   0   0   2\n",
      "   12   0   0   0   1   1   4   0]\n",
      " [  0 165   0  15   0   1   1   3  23   0   4   0   2   0   0   0   0  12\n",
      "    1   0   0   0   2   1   0   0]\n",
      " [  0   1 177   0   2   0   8   0   0   0  15   0   3   0   5   0   4   0\n",
      "    3   3   0   0   0   0   0   0]\n",
      " [  3  19   0 177   0   1   0   1   8   5   2   0   2   0  10   1   0   6\n",
      "    6   0   0   0   0   0   1   0]\n",
      " [  0   1   8   1  82   1  38   0  18   0  10   0   0   0   0   0  14   1\n",
      "   13   3   1   0   0  31   1   7]\n",
      " [  0   9   0   9   0 178   2   1   0   0   0   0   0   1   0   9  10   0\n",
      "    2   4   0   0   3   2   2   0]\n",
      " [  5   7  30   1   0   1 126   1   3   0   4   0   6   0   4   0  28   3\n",
      "    7   0   0   0   6   0   0   0]\n",
      " [  2  14   0  12   0   4   2  72   2   0   7   0   6   2  35   0   3  15\n",
      "    0   1   6   0   3  33   1   0]\n",
      " [  0   6   0  12   3   5   0   0 162  10   0   2   0   0   0   2   2   1\n",
      "   16   1   0   0   0   1   0   3]\n",
      " [  0   9   0   9   0   7   0   0   9 162   0   0   0   1   1   5   3   2\n",
      "   14   0   0   0   0   1   0   1]\n",
      " [  1   5   2   7  25   0   9   2   4   0 108   0   9   2   0   0   2  21\n",
      "    0   0   1   0   0  24   0   0]\n",
      " [  1   5   2   0   3   0   4   0   0   8  12 176   0   0   0   0  13   1\n",
      "    1   0   0   0   0   2   0   0]\n",
      " [  5   3   0   0   0   0   0   5   0   0   8   0 210   0   1   0   1   0\n",
      "    0   0   0   0   5   0   0   0]\n",
      " [  1   2   0  10   0   0   0  10   0   0   5   1   6 160   8   3   1   2\n",
      "    1   0   4   8  12   0   1   0]\n",
      " [  3   5   0   8   0   0   7   1  10   0   4   0   3   2 164   2   3  10\n",
      "    0   0   1   1   2   0   0   0]\n",
      " [  0   4   0   2   0  21   5   3   0   0   0   0   0   4   0 186   1   0\n",
      "    0   1   0   0  11   0   3   0]\n",
      " [  3   4   1   3   0   0   6   0   8   0   2   5   3   0  56   0 116   9\n",
      "   17   0   0   0   1   0   1   0]\n",
      " [  0  20   0  26   0   0   1  10   0   3   8   0   4   0   2   0   1 148\n",
      "    1   0   0   0   3   0   0   0]\n",
      " [ 15  46   0   5   5   4   0   2  21   2   1   0   0   0   0   0   9   4\n",
      "   60   3   0   1   0  24   0  22]\n",
      " [  0   0   1   1   4  10   8   2   0   0  12   0   0   0   1   0   2   0\n",
      "    5 166   3   4   0   3  17   0]\n",
      " [  0   0   1   0   0   0   2   9   0   0  10   1  22   5   9   0   1   0\n",
      "    0   0 181   1   1   1   0   0]\n",
      " [  0   9   0   0   0   2   0   2   0   0   0   0   4   1   0   2   0   0\n",
      "    1   0   0 190  15   0   3   0]\n",
      " [  0   2   0   0   0   0   0   2   0   0   0   0  16   2   5   0   0   0\n",
      "    0   0   0   9 190   0   0   0]\n",
      " [  0  12   0   1   9   0   0   1  18   1  14   1   0   0  43   0   1   2\n",
      "    8   6  10   0   1 102   1   5]\n",
      " [  0   0   0   2   0  22   0   0   0   0   0   0   2   1   0   2   9   0\n",
      "   10  45   4  55   4   0  80   0]\n",
      " [  3   0   1   1   8   2   0   0  22   2   2   5   0   0   0   0   1   0\n",
      "   29   4   0   0   0   7   2 131]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "df_letter = pd.read_csv(\"letter-recognition.data\", header=None)\n",
    "\n",
    "X = df_letter.iloc[:, 1:].values\n",
    "y = df_letter.iloc[:, 0].values\n",
    "\n",
    "print(\"Số mẫu:\", X.shape[0], \"Số feature:\", X.shape[1])\n",
    "print(\"Số lớp:\", len(set(y)))\n",
    "print(\"Một số dòng đầu tiên:\")\n",
    "print(df_letter.head())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Số mẫu train:\", X_train.shape[0])\n",
    "print(\"Số mẫu test:\", X_test.shape[0])\n",
    "\n",
    "class NaiveBayes:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.mean = {}\n",
    "        self.var = {}\n",
    "        self.priors = {}\n",
    "\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            self.mean[c] = X_c.mean(axis=0)\n",
    "            self.var[c] = X_c.var(axis=0)\n",
    "            self.priors[c] = X_c.shape[0] / X.shape[0]\n",
    "\n",
    "    def _pdf(self, class_idx, x):\n",
    "        mean = self.mean[class_idx]\n",
    "        var = self.var[class_idx]\n",
    "        numerator = np.exp(- (x - mean) ** 2 / (2 * var))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        return numerator / denominator\n",
    "\n",
    "    def _predict_single(self, x):\n",
    "        posteriors = []\n",
    "        for c in self.classes:\n",
    "            prior = np.log(self.priors[c])\n",
    "            conditional = np.sum(np.log(self._pdf(c, x)))\n",
    "            posterior = prior + conditional\n",
    "            posteriors.append(posterior)\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_single(x) for x in X])\n",
    "\n",
    "nb_letter = NaiveBayes()\n",
    "nb_letter.fit(X_train, y_train)\n",
    "y_pred = nb_letter.predict(X_test)\n",
    "\n",
    "print(\"Accuracy trên Letter dataset:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
