{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6c085fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tên các cột: ['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species']\n",
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n",
      "\n",
      "Có giá trị thiếu không:\n",
      "Id               0\n",
      "SepalLengthCm    0\n",
      "SepalWidthCm     0\n",
      "PetalLengthCm    0\n",
      "PetalWidthCm     0\n",
      "Species          0\n",
      "dtype: int64\n",
      "Số mẫu train: 105\n",
      "Số mẫu test: 45\n",
      "Độ chính xác trên tập test: 1.0\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        15\n",
      "Iris-versicolor       1.00      1.00      1.00        15\n",
      " Iris-virginica       1.00      1.00      1.00        15\n",
      "\n",
      "       accuracy                           1.00        45\n",
      "      macro avg       1.00      1.00      1.00        45\n",
      "   weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 15]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from collections import Counter # Thêm thư viện này để đếm (bỏ phiếu)\n",
    "\n",
    "# 1️⃣ Load dữ liệu từ file Iris.csv\n",
    "df = pd.read_csv(\"Iris.csv\")\n",
    "\n",
    "# Kiểm tra tên cột\n",
    "print(\"Tên các cột:\", df.columns.tolist())\n",
    "print(df.head())\n",
    "\n",
    "# Giả sử cột label là 'species'\n",
    "X = df.iloc[:, :-1].values  # 4 cột đầu là features\n",
    "y = df.iloc[:, -1].values   # cột cuối là label\n",
    "\n",
    "# 2️⃣ Kiểm tra dữ liệu thiếu\n",
    "print(\"\\nCó giá trị thiếu không:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 3️⃣ Chia dữ liệu train/test (70% train, 30% test, giữ cân bằng lớp)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Số mẫu train:\", X_train.shape[0])\n",
    "print(\"Số mẫu test:\", X_test.shape[0])\n",
    "\n",
    "# 4️⃣ Lớp KNN\n",
    "class KNN:\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # \"Huấn luyện\" KNN chỉ là lưu trữ dữ liệu\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def _euclidean_distance(self, x1, x2):\n",
    "        # Hàm tính khoảng cách\n",
    "        return np.sqrt(np.sum((x1 - x2)**2))\n",
    "\n",
    "    def _predict_single(self, x):\n",
    "        # 1. Tính khoảng cách từ x đến tất cả các điểm train\n",
    "        distances = [self._euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        \n",
    "        # 2. Lấy chỉ số của k điểm gần nhất\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        \n",
    "        # 3. Lấy nhãn của k điểm đó\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        \n",
    "        # 4. Bỏ phiếu: Lấy nhãn xuất hiện nhiều nhất\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_single(x) for x in X])\n",
    "\n",
    "# 5️⃣ Huấn luyện và dự đoán\n",
    "knn = KNN(k=5) # Chọn k=5\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# 6️⃣ In kết quả\n",
    "print(\"Độ chính xác trên tập test:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11500049-f0c7-4796-8853-48b407c6f38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy trên Letter dataset: 0.947\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.99      0.99      0.99       237\n",
      "           B       0.90      0.94      0.92       230\n",
      "           C       0.93      0.96      0.95       221\n",
      "           D       0.88      0.98      0.93       242\n",
      "           E       0.86      0.93      0.90       230\n",
      "           F       0.95      0.93      0.94       232\n",
      "           G       0.95      0.90      0.92       232\n",
      "           H       0.84      0.89      0.87       220\n",
      "           I       0.96      0.96      0.96       226\n",
      "           J       0.96      0.94      0.95       224\n",
      "           K       0.91      0.87      0.89       222\n",
      "           L       0.98      0.98      0.98       228\n",
      "           M       0.98      0.97      0.97       238\n",
      "           N       0.96      0.93      0.94       235\n",
      "           O       0.90      0.93      0.91       226\n",
      "           P       0.97      0.95      0.96       241\n",
      "           Q       0.97      0.95      0.96       235\n",
      "           R       0.94      0.89      0.92       227\n",
      "           S       0.98      0.94      0.96       224\n",
      "           T       0.97      0.97      0.97       239\n",
      "           U       0.98      0.98      0.98       244\n",
      "           V       0.97      0.96      0.96       229\n",
      "           W       0.98      0.97      0.98       226\n",
      "           X       0.97      0.94      0.96       236\n",
      "           Y       0.97      0.97      0.97       236\n",
      "           Z       0.97      0.99      0.98       220\n",
      "\n",
      "    accuracy                           0.95      6000\n",
      "   macro avg       0.95      0.95      0.95      6000\n",
      "weighted avg       0.95      0.95      0.95      6000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[235   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0 217   0   0   1   0   0   4   0   0   0   0   0   0   0   0   0   5\n",
      "    1   0   1   1   0   0   0   0]\n",
      " [  0   0 212   0   1   0   2   0   0   0   0   0   0   1   3   0   1   0\n",
      "    0   0   0   0   1   0   0   0]\n",
      " [  0   0   0 236   0   0   1   4   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   1   0   0]\n",
      " [  0   0   7   0 215   1   2   0   0   0   1   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   1   0   3]\n",
      " [  0   1   0   2   1 216   0   1   0   0   0   0   0   2   0   5   0   0\n",
      "    0   2   0   0   2   0   0   0]\n",
      " [  0   2   0   4  13   0 208   1   0   0   0   0   1   0   3   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   3   0   7   2   0   1 196   0   0   5   0   0   0   1   0   0   3\n",
      "    1   0   0   0   0   0   0   1]\n",
      " [  0   0   0   1   1   1   0   0 216   7   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   1   0   0  10 211   0   1   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   1   0   1   4   0   0  13   0   0 194   0   0   0   0   0   0   2\n",
      "    0   0   1   0   0   6   0   0]\n",
      " [  0   0   0   0   3   0   2   0   0   0   0 223   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   0 231   3   2   0   0   0\n",
      "    0   0   0   0   1   0   0   0]\n",
      " [  1   1   0   5   0   0   0   4   0   0   0   1   1 218   1   0   0   1\n",
      "    0   0   0   2   0   0   0   0]\n",
      " [  0   1   2   6   0   0   1   0   0   0   0   0   0   1 210   0   3   1\n",
      "    0   0   1   0   0   0   0   0]\n",
      " [  0   1   0   0   1   8   0   1   0   0   0   0   0   0   0 229   0   0\n",
      "    0   0   0   0   0   0   1   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   8   1 224   1\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   8   0   1   1   0   0   3   0   0   7   2   0   2   0   0   0 203\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   1   0   3   2   0   0   3   0   1   0   0   0   0   0   0   0   0\n",
      "  211   1   0   0   0   0   0   2]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0\n",
      "    0 231   0   1   0   0   5   0]\n",
      " [  0   0   1   0   0   0   0   2   0   0   1   0   1   0   1   0   0   0\n",
      "    0   0 238   0   0   0   0   0]\n",
      " [  0   3   1   0   0   1   0   0   0   0   0   0   0   0   1   0   0   0\n",
      "    0   0   3 219   0   0   1   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   2   0   3   0   0   0\n",
      "    0   0   0   0 220   0   0   0]\n",
      " [  0   0   1   1   4   0   0   0   0   0   6   0   0   0   0   0   0   0\n",
      "    1   0   0   0   0 223   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
      "    0   3   0   2   0   0 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0\n",
      "    1   0   0   0   0   0   0 217]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 1️⃣ Load dữ liệu Letter\n",
    "df_letter = pd.read_csv(\"letter-recognition.data\", header=None)\n",
    "X = df_letter.iloc[:, 1:].values\n",
    "y = df_letter.iloc[:, 0].values\n",
    "\n",
    "# 2️⃣ Chia dữ liệu train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3️⃣ Lớp kNN vector hóa với NumPy\n",
    "class KNN:\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Tính khoảng cách Euclidean giữa tất cả X và X_train (vector hóa)\n",
    "        # Dùng công thức ||a-b||^2 = ||a||^2 + ||b||^2 - 2*a.b\n",
    "        X_norm = np.sum(X**2, axis=1).reshape(-1, 1)\n",
    "        X_train_norm = np.sum(self.X_train**2, axis=1).reshape(1, -1)\n",
    "        distances = np.sqrt(X_norm + X_train_norm - 2 * X.dot(self.X_train.T))\n",
    "\n",
    "        # Lấy k nearest neighbors và dự đoán\n",
    "        k_indices = np.argsort(distances, axis=1)[:, :self.k]\n",
    "        k_nearest_labels = self.y_train[k_indices]\n",
    "\n",
    "        # Dự đoán nhãn xuất hiện nhiều nhất\n",
    "        y_pred = []\n",
    "        for labels in k_nearest_labels:\n",
    "            values, counts = np.unique(labels, return_counts=True)\n",
    "            y_pred.append(values[np.argmax(counts)])\n",
    "        return np.array(y_pred)\n",
    "\n",
    "# 4️⃣ Huấn luyện và dự đoán\n",
    "knn_letter = KNN(k=5)\n",
    "knn_letter.fit(X_train, y_train)\n",
    "y_pred = knn_letter.predict(X_test)\n",
    "\n",
    "# 5️⃣ In kết quả\n",
    "print(\"Accuracy trên Letter dataset:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f7bf2f-a1f5-40d5-92d0-538374006e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
